<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="content-type" content="text/html;
      charset=windows-1252">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link type="text/css" href="../../css/blog.css" media="all" rel="stylesheet">
  <title></title>
</head>

<body>

  <div class="header">
    <table id="headerline_table">
      <tr>
        <td width="200">
          <a href="../../index.html"><img src="../../images/home.png" alt="home" height="60"></a>
          <a href="../../blogs/index.html"><img src="../../images/scroll.png" alt="scroll" height="60"></a>
          <a href="../../blogs/AI_learning/index.html"><img src="../../images/AI_01.png" alt="deno" height="60"></a>
        </td>
        <td>
          <h2>AI learning blog May 2025 </h2>
        </td>
      </tr>
    </table>
  </div>


  <div class="row">
    <div class="leftcolumn">


      <div class="card">
        <h2>May 10, 2025</h2>
        J. Heaton class chapter 8.2, "Evaluating Feature Importance"<br><br>

        "More important inputs will produce a less accuratescore when they are removed by shuffling them."<br<br>

          The function perturbation_rank() works as follows:<br><br>
          - shuffle each input column<br>
          - compute the prediction<br>
          - compute the error as log_loss between prediction and actual y values.<br>
          <br>
          The following table shows the difference between prediction and y in each case:<br><br>
          <table style="width: 50%">
            <tr>
              <td>sl</td>
              <td>sw</td>
              <td>pl</td>
              <td>pw</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>-1</td>
              <td>1</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>1</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>0</td>
              <td>0</td>
            </tr>
            <tr>
              <td>1</td>
              <td>0</td>
              <td>0</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>0</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>1</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>-1</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>-1</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>0</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>-1</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>-2</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>0</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>1</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>2</td>
              <td>1</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>1</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>1</td>
              <td>-1</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>0</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>-1</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>1</td>
              <td>1</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>-1</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>1</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>-1</td>
              <td>-1</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>0</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>0</td>
              <td>-1</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>-2</td>
              <td>-1</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>0</td>
              <td>-1</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>-2</td>
              <td>-1</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>0</td>
              <td>-1</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>1</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>1</td>
              <td>1</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>0</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>0</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>1</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>2</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>0</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>-1</td>
              <td>-1</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>0</td>
              <td>0</td>
            </tr>
            <tr>
              <td>0</td>
              <td>0</td>
              <td>1</td>
              <td>0</td>
            </tr>
          </table>
          <br>
          It is apparent that the column petal_l has far more errors than the other columns, therefore it is regarded as
          more important.

      </div>


      <div class="card">
        <h2>May 14, 2025</h2>

        The code in the chapter "Biological Response with Neural Network" in module 8 part 2 does not run, giving the
        error:<br>
        <div class="output">
          ModuleNotFoundError: No module named 'tensorflow.keras.wrappers'
        </div>

        Brave search "ModuleNotFoundError: No module named 'tensorflow.keras.wrappers'",<br>
        AI recommends two options:<br>
        <p>
          "As of TensorFlow 2.15, the wrappers submodule under tensorflow.keras has been removed. To resolve this issue,
          you can either uninstall the current version of TensorFlow and install an earlier version where the wrappers
          submodule is still available,"
        </p>
        <h5>Attempt 1</h5>
        <div class="code">
          pip install scikeras
        </div>
        in the existing jh_class environment failed.
        failed

        <h5>Attempt 2</h5>
        <div class="code">
          conda create -n ensemble python=3.7
        </div>
        <div class="code">
          conda install -c conda-forge numpy -y<br>
          conda install -c conda-forge pandas -y<br>
          conda install -c conda-forge tensorflow -y<br>
          pip install scikit-learn<br>
        </div>
        This works.

        <a href=""> </a><br>
      </div>

      <div class="card">
        <h2>May 15, 2025</h2>

        The jupyter notebook shows a depracation warning, recommending to visit<br>

        <a href="https://adriangb.com/scikeras/stable/migration.html">
          https://adriangb.com/scikeras/stable/migration.html </a><br>

        <br>

        <a href="https://adriangb.com/scikeras/stable/">
          https://adriangb.com/scikeras/stable/ </a><br>
        <br>


        <a href=""> </a><br>
      </div>


      <div class="card">
        <h2>May 16, 2025</h2>

        <h5>model.predict_proba()</h5>
        What does model.predict_proba() do? <br>
        <br>
        Brave search "proba returns two values":<br>
        The predict_proba function in scikit-learn returns an array where each row corresponds to a sample and each
        column corresponds to a class probability. When there are two classes, the function returns a 2-column array,
        where the first column represents the probability of the sample belonging to the first class, and the second
        column represents the probability of the sample belonging to the second class.<br>
        Example:
        <div class="output">
          [0.3 0.7 ]<br>
          [0.68 0.32]<br>
          [0.47 0.53]
        </div>
        For the first sample, the probability for the first class is 30%, and for the second class it is 70%.<br>
        <br>
        Where is the source code for the function predict_proba() ?<br>
        <br>
        Open terminal.<br>
        <div class="code">
          cd ~/miniconda3/envs/ensemble/lib/python3.7<br>
          grep -r "def predict_proba("
        </div>
        This will list a number of files, such as<br>
        <div class="output">
          site-packages/keras/wrappers/scikit_learn.py:<br>
          def predict_proba(self, x, **kwargs):
        </div>
        This is the function that is called when the model is Sequential().<br>
        <br>
        Deprecation warning<br><br>
        Brave search "kera api predict_proba":<br>
        "this function has been deprecated in Tensorflow version 2.6 and later versions of Keras. Instead, you should
        use the predict() function directly to achieve similar results."<br>


        <a href=""> </a><br>
      </div>

      <div class="card">
        <h2>May 16, 2025</h2>
        <h3>Structure of class_08_2_keras_ensembles_bio_blend.py</h3>

        <h5>main program</h5>
        The file bio_train.csv contains the training data.<br>
        It contains and 3751 rows and 1777 columns.<br>
        The first column named "activity" is the target.<br>
        All the other columns are the predictors.<br>
        <ul>
          <li>The predictor values are read into the variable x and it is of shape (3751, 1776)</li>
          <li>The target values are read into the variable y and it is of shape (3751,)</li>
        </ul>
        The file bio_test.csv contains the data for which a prediction will be made.<br>
        It contains and 2501 rows and 1776 columns.<br>
        Since it is meant for the Kaggle submission, it does not contain the target
        column ("solution")<br>
        <ul>
          <li>The predictor values for the submission are read into the variable x_submit and it is of shape (2501,
            1776)</li>
        </ul>

        The blend_ensemble(x, y, x_submit) is called and it returns the variable submit_data which is of shape (2501,
        2).<br>
        <br>
        The values in submit_data are then stretched such that the smallest value becomes 0 and the largest value
        becomes 1.<br>
        <br>
        Finally, an index column and the column 1 (second column) of submit_data are provided with the labels
        "MoleculeId" and "PredictedProbability" and saved to the submission file named "submit.csv".

        <a href=""> </a><br>
      </div>

      <div class="card">
        <h2>May 18, 2025</h2>

        <h5>blend_ensemble() function</h5>
        The blend_ensemble() function starts by generating the indices for a stratified KFold.<br>
        Use<br>
        <ul>
          <li>KFold When dealing with a regression problem.</li>
          <li>StratifiedKFold When dealing with a classification problem.</li>
        </ul>

        <h5>Use of a Stratified KFold with a single model</h5>

        The function
        <div class="code">
          kf.split(x,y)
        </div>
        simply generates indices for the elements of the dataset.<br><br>

        Each fold contains the indices of all elements, just in different variations.<br><br>
        Example:<br>
        The dataset is
        <div class="code">
          x = np.array([[1.1, 1.2], [2.1, 2.2], [3.1, 3.2], [4.1, 4.2], [5.1,5.2], [6.1, 6.2]])<br>
          y = np.array(["cat", "rabbit", "rabbit", "cat", "rabbit", "cat"])
        </div>
        Then the code
        <div class="code">
          kf = StratifiedKFold(2)<br>
          for i, (train_index, test_index) in enumerate(kf.split(x,y)):<br>
          print() etc.
        </div>
        produces the following 2 folds:<br>
        <table style="width:90%">
          <tr>
            <th> </th>
            <th> Fold 0</th>
            <th> Fold 1</th>
          </tr>
          <tr>
            <td style="width:10%">
              <br>
              index<br>
              x values<br>
              y values<br><br>
              <br>
              index<br>
              x values<br>
              y values
            </td>
            <td style="width:40%">
              Train:<br>
              [2 4 5]<br>
              [[3.1 3.2]
              [5.1 5.2]
              [6.1 6.2]]<br>
              ['rabbit' 'rabbit' 'cat']<br><br>
              Test:<br>
              [0 1 3]<br>
              [[1.1 1.2]
              [2.1 2.2]
              [4.1 4.2]]<br>
              ['cat' 'rabbit' 'cat']
            </td>
            <td style="width:40%">
              Train:<br>
              [0 1 3]<br>
              [[1.1 1.2]
              [2.1 2.2]
              [4.1 4.2]]<br>
              ['cat' 'rabbit' 'cat']<br><br>
              Test:<br>
              [2 4 5]<br>
              [[3.1 3.2]
              [5.1 5.2]
              [6.1 6.2]]<br>
              ['rabbit' 'rabbit' 'cat']
            </td>
          </tr>
        </table>

        <img src="images/kfolds1.png" alt="kfolds1" width="700">

        <h5>Using Stratified KFolds with Ensembles</h5>
        The blend_ensemble() function receives the parameters x,y, and x_submit and creates a stratified K-Fold with the
        parameters for the predictors and targets from the file bio_train.csv.

        <div class="code">
          folds = list(kf.split(x, y))
        </div>
        The list() function converts the folds into an array of the folds.<br>
        <br>
        The program then creates an array of various models.<br>
        <br>
        Two new variables dataset_blend_train and dataset_blend_test are created
        to hold the predictions for later blending:<br>
        <br>
        dataset_blend_train is of shape (3751,7)<br>
        - 3751 is the number of rows in the training and 7 is the number of models
        <br><br>
        dataset_blend_test is of shape (2501,7)<br>
        - 2501 is the number of rows in the submit data and 7 is the number of models



        <a href=""> </a><br>
      </div>

      <div class="card">
        <h2>May 20, 2025</h2>
        <h5>blend_ensemble() function continued</h5>

        The code then contains a nested loop:<br>
        - the outer loop iterates over the 7 models<br>
        - the inner loop iterates over the 10 folds.<br>
        <br>
        The outer loop begins by creating the variable named fold_sums which is of shape (3751,10).<br>
        The columns of this variable will be filled in the inner loop with values that pertain to the submit
        dataset.<br><br>

        In the inner loop, the predictors for training and testing are read into the variables x_train and x_test,
        using the indices of each according fold.<br>
        Since the number of folds is 10, x_train will have 3376 rows and x_test will have 375 rows.<br>
        3376+375=3751<br>
        <br>
        The target values are read into the variables y_train and y_test in an equivalent manner.<br>
        <br>
        Then the model (which is selected in the outer loop from 7 models) is trained.<br>
        <br>
        The predictions for x_test are stored in the variable named pred.<br>
        <br>

        The following line fills up the (3751,7) array named dataset_blend_train with the predictions for each
        model (j is the loop variable for the models):<br>
        <div class="code">
          dataset_blend_train[test, j] = pred[:, 1]
        </div>
        Because we are working with 10 folds, we only get 375 values in each fold iteration.<br>
        (376 values in the first fold because 3751 doesn't divide by ten)<br>
        <br>
        Each prediction is placed in the correct row in dataset_blend_train by making use of the indices that are stored
        in the test variable.<br>
        <br>
        Simplified Example:<br>

        <img src="images/ensemble_folds.png" alt="ensemble_folds" width="800">
        <br>
        The animation shows how the predictions are placed in the correct locations in the dataset_blend_train
        variable:<br><br>
        <div style="text-align:left">
          <button onclick="playPause()">Play/Pause</button>
          <button onclick="makeBig()">Big</button>
          <button onclick="makeSmall()">Small</button>
          <button onclick="makeNormal()">Normal</button>
          <br><br>
          <video id="video1" width="420">
            <source src="images/ensemble_folds.webm" type="video/webm">
            <source src="mov_bbb.ogg" type="video/ogg">
            Your browser does not support HTML video.
          </video>
        </div>
        <script>
          var myVideo = document.getElementById("video1");

          function playPause() {
            if (myVideo.paused)
              myVideo.play();
            else
              myVideo.pause();
          }

          function makeBig() {
            myVideo.width = 560;
          }

          function makeSmall() {
            myVideo.width = 320;
          }

          function makeNormal() {
            myVideo.width = 420;
          } 
        </script>



        <a href=""> </a><br>
      </div>

      <div class="card">
        <h2>May 23, 2025</h2>
        <h5>blend_ensemble() function continued</h5>

        The model is used again to compute the predictions for the submit dataset.<br>
        The predicitions are stored in the pred2 variable.<br>
        For each fold in the current model, the predicitions are saved in the fold_sums variable.<br>
        <br>

        After the loop for the folds has completed, we end up with a fold_sums variable that contains the predictions
        for the submit inputs, for each of the ten folds.<br>
        <br>
        The code now computes the mean value for each row in the fold_sums variable and stores it in the according
        column of the dataset_blend_test variable.<br>
        <br>
        At the end of the nested loop, we have two variables containing predictions:<br>
        <br>

        <img src="images/dataset_blend.png" alt="dataset_blend" width="500">

        <br>
        where the predictions in dataset_blend_train originated from the training data,<br>
        and the predictions in dataset_blend_test originated from the submit data.<br>
        <br><br>
        The final step is the blending of the models.<br>
        <br>


        The code uses Logistic Regression (from scikit-learn) to blend the models in order to get a better prediction
        out of the training data.<br>
        <br>

        <a href="https://www.digitalocean.com/community/tutorials/logistic-regression-with-scikit-learn">
          https://www.digitalocean.com/community/tutorials/logistic-regression-with-scikit-learn </a><br>

        <br>
        The line
        <div class="code">
          blend.fit(dataset_blend_train, y)
        </div>
        trains the model variable named blend with the predicitions from the training data.<br>
        <br>
        The line
        <div class="code">
          blend.predict_proba(dataset_blend_test)
        </div>
        computes the predictions for the submit data.<br>

        <a href=""> </a><br>
      </div>



      <div class="card">
        <h2>May 24, 2025</h2>
        Module 8.4, Bayesian Hyperparameter
        Optimization for Keras<br>
        <br>
        Code works on laptop without GPU.<br>
        On server with GPU and CUDA installed, get error
        <div class="output">
          ValueError: Cannot convert '(500, 125.0)' to a shape. Found invalid entry '125.0' of type '<class 'float'>'.
        </div>

        Changing line
        <div class="code">
          neuronCount = neuronCount * neuronShrink
        </div>
        to
        <div class="code">
          neuronCount = round(neuronCount * neuronShrink)
        </div>
        solves the problem.<br>

        <a href=""> </a><br>
      </div>



      <div class="card">
        <h2>Date</h2>
        <a href=""> </a><br>
      </div>



    </div>

    <div class="rightcolumn">
      <div class="card">
        <h3>Posts by Date</h3>
        <a href="AI_learning_2023_02_feb.html">
          AI_learning_2023_02_feb.html</a><br>
        <a href="AI_learning_2023_03_mar.html">
          AI_learning_2023_03_mar.html</a><br>
        <br>
      </div>

      <div class="card">
        <h3>Follow Me</h3>
        <a href="https://discord.gg/F7KQySEW"><img src="../../images/discord.png" alt="discord" height="30"></a>
      </div>

    </div>



  </div>


  <div class="footer">
    <h3>Modified July 2023</h3>
  </div>
</body>

</html>