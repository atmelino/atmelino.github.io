<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="content-type" content="text/html;
      charset=windows-1252">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link type="text/css" href="../../css/blog.css" media="all" rel="stylesheet">
  <title>atmelino</title>
</head>

<body>

  <div class="header">
    <table id="headerline_table">
      <tr>
        <td width="200">
          <a href="../../index.html"><img src="../../images/home.png" alt="home" height="60"></a>
          <a href="../../blogs/index.html"><img src="../../images/scroll.png" alt="scroll" height="60"></a>
          <a href="../../blogs/AI_learning/index.html"><img src="../../images/AI_01.png" alt="deno" height="60"></a>
        </td>
        <td>
          <h2>AI learning blog September 2025 </h2>
        </td>
      </tr>
    </table>
  </div>


  <div class="row">
    <div class="leftcolumn">


      <div class="card">
        <h2>September 3, 2025</h2>

        Observation:<br>

        Display an image in VSCodium, loaded from a local file location.<br>
        Delete the file, VSCodium still displays the image.<br>
        OS call to ls shows that the file does not exist.<br>
        Is there some sort of cache?<br>
        <br>
        Answer:<br>
        "The keras.utils.get_file function downloads a file from a specified URL if it is not already present in the
        local cache.<br>
        By default, the file is saved to the directory ~/.keras/datasets/"<br>
        <br>

        <a href="https://keras.io/api/utils/python_utils/#getfile-function">
          https://keras.io/api/utils/python_utils/#getfile-function</a><br>
        <a href=""> </a><br>
      </div>


      <div class="card">
        <h2>September 8, 2025</h2>
        How does the code for Neural style transfer generate the combined image?<br>
        <br>
        <a href="https://keras.io/examples/generative/neural_style_transfer">
          https://keras.io/examples/generative/neural_style_transfer </a><br>
        <br>
        At the beginning of the code, the variable combination_image is loaded with the data from the base image.<br>
        <div class="code">
          combination_image = tf.Variable(preprocess_image(base_image_path))
        </div>
        <br>
        The loop for the optimization contains a call apply gradients:<br>
        <br>
        <div class="code">
          optimizer.apply_gradients([(grads, combination_image)])
        </div>

        <a href="https://keras.io/api/optimizers/">https://keras.io/api/optimizers/ </a><br>
        <a href="https://keras.io/api/optimizers/#applygradients-method">
          https://keras.io/api/optimizers/#applygradients-method
        </a><br>

        <a href=""> </a><br>
      </div>

      <div class="card">
        <h2>September 9, 2025</h2>

        The following line instantiates a class of the type Model:<br>
        <div class="code">
          feature_extractor = keras.Model(inputs=model.inputs, outputs=outputs_dict)
        </div>

        Model class in keras:<br>
        <a href="https://keras.io/api/models/model/#model-class">
          https://keras.io/api/models/model/#model-class
        </a><br>

        <a href=""> </a><br>
      </div>

      <div class="card">
        <h2>September 10, 2025</h2>
        Observations:<br>
        if we remove the line
        <div class="code">
          optimizer.apply_gradients([(grads, combination_image)])
        </div>
        then the loss remains constant throughout the loop, and the combination image remains the same.<br>
        <br>
        This proves that this is the line that modifies the combination image.<br>
        <br>

        <a href=""> </a><br>
      </div>

      <div class="card">
        <h2>September 11, 2025</h2>
        Starting with the optimization loop and working our way back from these statements in order to understand the
        rest of the algorithm:<br>
        <br>
        The following two lines in the optimization loop make up the generation of the combined image:<br>
        <br>
        <div class="code">
          loss, grads = compute_loss_and_grads( combination_image, base_image, style_reference_image )<br>
          <br>
          optimizer.apply_gradients([(grads, combination_image)])
        </div>
        <br>
        The first statement computes the gradients that point in the direction of a loss reduction.<br>
        For this, the tf.GradientTape() function is used.<br>
        <br>
        Then, with the second statement, we move to a new point in the combination_image space going in the direction of
        a lower loss by applying the gradients to the combination_image.<br>
        <br>
        In the next iteration, the new value of combination_image serves as an input for the next gradient generation,
        thus creating a loop that leads to a minimum.<br>
        <br>
        <br>
        What do tf.GradientTape() and apply_gradients() do?<br>
        <br>
        Using TensorFlow and GradientTape to train a Keras model<br>
        <a href="https://pyimagesearch.com/2020/03/23/using-tensorflow-and-gradienttape-to-train-a-keras-model/">
          https://pyimagesearch.com/2020/03/23/using-tensorflow-and-gradienttape-to-train-a-keras-model/ </a><br>

        <div class="code">
          grads = tape.gradient(loss, model.trainable_variables)<br>
          <br>
          opt.apply_gradients(zip(grads, model.trainable_variables))
        </div>
        <br>

        What is the purpose of the Tensorflow Gradient Tape?<br>
        <a href="https://stackoverflow.com/questions/53953099/what-is-the-purpose-of-the-tensorflow-gradient-tape">
          https://stackoverflow.com/questions/53953099/what-is-the-purpose-of-the-tensorflow-gradient-tape </a><br>

        <a href=""> </a><br>
      </div>



      <div class="card">
        <h2>September 12, 2025</h2>

        Neural Transfer Using PyTorch<br>
        <a href="https://docs.pytorch.org/tutorials/advanced/neural_style_tutorial.html#style-loss">
          https://docs.pytorch.org/tutorials/advanced/neural_style_tutorial.html#style-loss
        </a><br>
        <br>

        tf.GradientTape in TensorFlow<br>
        <a href="https://www.geeksforgeeks.org/deep-learning/tf-gradienttape-in-tensorflow/">
          https://www.geeksforgeeks.org/deep-learning/tf-gradienttape-in-tensorflow/
        </a><br>
        <br>
        Simple example computing the derivative of x^2<br>
        <div class="code">
          scalar = tf.Variable(3.0)<br>
          with tf.GradientTape() as tape:<br>
          &nbsp y = scalar**2<br>
          dy_dx = tape.gradient(y, scalar)
        </div>
        tape.gradient computes the gradient (derivative) of y with respect to scalar.<br>
        <br>
        fchollet style transfer example:<br>
        <div class="code">
          with tf.GradientTape() as tape:<br>
          &nbsp loss = compute_loss(combination_image, base_image, style_reference_image)<br>
          grads = tape.gradient(loss, combination_image)<br>
          optimizer.apply_gradients([(grads, combination_image)])
        </div>
        tape.gradient computes the gradient of loss with respect to combination_image.<br>

        <a href=""> </a><br>
      </div>



      <div class="card">
        <h2>September 15, 2025</h2>
        This guide makes use of tf.GradientTape:<br>
        <br>
        Writing a training loop from scratch in TensorFlow<br>
        <a href="https://keras.io/guides/writing_a_custom_training_loop_in_tensorflow/">
          https://keras.io/guides/writing_a_custom_training_loop_in_tensorflow/ </a><br>
        <br>

        Online courses<br>
        Introduction to TensorFlow<br>
        <a
          href="https://codefinity.com/courses/v2/a668a7b9-f71f-420f-89f1-71ea7e5abbac/06e03ca8-c595-4f4d-9759-ad306980f0e9/b06d492a-949b-4b71-80ee-21d6b3b69aa0">
          https://codefinity.com/courses/v2/a668a7b9-f71f-420f-89f1-71ea7e5abbac/06e03ca8-c595-4f4d-9759-ad306980f0e9/b06d492a-949b-4b71-80ee-21d6b3b69aa0
        </a><br>
        <br>
        Introduction to gradients and automatic differentiation<br>
        <a href="https://www.tensorflow.org/guide/autodiff"> https://www.tensorflow.org/guide/autodiff</a><br>


        <a href=""> </a><br>
      </div>



      <div class="card">
        <h2>September 16, 2025</h2>

        Linear Regression with tf.GradientTape:<br>
        <a href="https://www.linkedin.com/pulse/gradient-tape-deploy-descent-tensorflow-vu-hong-quan">
          https://www.linkedin.com/pulse/gradient-tape-deploy-descent-tensorflow-vu-hong-quan
        </a><br>

        <a href="https://github.com/quanvu0996/data_science/blob/main/tf/gradient_tape1_en.ipynb">
          https://github.com/quanvu0996/data_science/blob/main/tf/gradient_tape1_en.ipynb
        </a><br>

        <br>

        Comparison between using model.fit() versus tf.GradientTape:<br>
        <a href="https://medium.com/@bjorn_sing/tensorflow-gradient-tape-mnist-536c47fb8d85">
          https://medium.com/@bjorn_sing/tensorflow-gradient-tape-mnist-536c47fb8d85
        </a><br>
        <a href="https://www.kaggle.com/code/bjoernjostein/train-keras-model-using-gradient-tape">
          https://www.kaggle.com/code/bjoernjostein/train-keras-model-using-gradient-tape </a><br>

        <br>

        Simple example where model.fit() is replaced with tf.GradientTape:<br>
        <a href="https://pyimagesearch.com/2024/08/12/how-to-use-tf-gradienttape/">
          https://pyimagesearch.com/2024/08/12/how-to-use-tf-gradienttape/
        </a><br>


        <br>
        <br>
        Another tutorial on neural style transfer<br>
        with explanation why VGG19 model is used<br>
        <a href="https://www.tensorflow.org/tutorials/generative/style_transfer">
          https://www.tensorflow.org/tutorials/generative/style_transfer
        </a><br>

        <a href=""> </a><br>
      </div>


      <div class="card">
        <h2>September 26, 2025</h2>

        Writing a training loop from scratch in TensorFlow<br>
        <a href="https://keras.io/guides/writing_a_custom_training_loop_in_tensorflow/">
          https://keras.io/guides/writing_a_custom_training_loop_in_tensorflow/
        </a><br>
        <br>
        The mnist dataset consists of 70,000 images and labels. <br>
        The images are hand-written numbers, and the labels are the correct associated numbers.<br>

        <a href="https://keras.io/api/datasets/mnist/">
          https://keras.io/api/datasets/mnist/ </a><br>
        <br>
        The line<br>
        <div class="code">
          (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
        </div>
        returns<br>
        - 60,000 images and correct classifications into the variables x_train and y_train<br>
        - 10,000 images and correct classifications into the variables x_test, y_test<br>
        <br>
        (x_train, y_train) are to be used for training<br>
        (x_test, y_test) are to be used for validation<br>
        <br>

        The variables x_train and x_test contain the images of 28 by 28 pixels.<br>
        The value of the array element at (i,j) is the gray-scale value of the pixel coordinate (i,j)<br>
        <br>
        As a result, the shape of x_train is<br>
        <div class="code">
          print(x_train.shape)
        </div>
        <div class="output">
          (60000, 28, 28)
        </div>
        <br>
        The training code works with a dense 1-dimensional model.<br>
        Therefore, the images data arrays are flattened into a 1-dimensional array:<br>
        <div class="code">
          x_train = np.reshape(x_train, (-1, 784))
        </div>



        <a href=""> </a><br>

      </div>




    </div>

    <div class="rightcolumn">
      <div class="card">
        <h3>Posts by Date</h3>
        <a href="AI_learning_2023_02_feb.html">
          AI_learning_2023_02_feb.html</a><br>
        <a href="AI_learning_2023_03_mar.html">
          AI_learning_2023_03_mar.html</a><br>
        <br>
      </div>

      <div class="card">
        <h3>Follow Me</h3>
        <a href="https://discord.gg/F7KQySEW"><img src="../../images/discord.png" alt="discord" height="30"></a>
      </div>

    </div>



  </div>


  <div class="footer">
    <h3>Modified July 2023</h3>
  </div>
</body>

</html>