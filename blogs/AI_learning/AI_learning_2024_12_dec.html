<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="content-type" content="text/html;
      charset=windows-1252">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link type="text/css" href="../../css/blog.css" media="all" rel="stylesheet">
  <title></title>
</head>

<body>

  <div class="header">
    <table id="headerline_table">
      <tr>
        <td width="200">
          <a href="../../index.html"><img src="../../images/home.png" alt="home" height="60"></a>
          <a href="../../blogs/index.html"><img src="../../images/scroll.png" alt="scroll" height="60"></a>
          <a href="../../blogs/AI_learning/index.html"><img src="../../images/AI_01.png" alt="deno" height="60"></a>
        </td>
        <td>
          <h2>AI learning blog December 2024 </h2>
        </td>
      </tr>
    </table>
  </div>


  <div class="row">
    <div class="leftcolumn">

      <div class="card">
        <h2>December 03, 2024</h2>

        "A Gentle Introduction to the Bootstrap Method"<br><br>
        <a href="https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/">
          https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/ </a><br>

      </div>

      <div class="card">
        <h2>December 06, 2024</h2>
        Class 7.1 is missing from the repository of Jeff Heaton, but this fork contains the missing file:<br><br>
        <a href="https://github.com/facugonz/pytorch_installing/blob/master/t81_558_class_07_1_gan_intro.ipynb">
          https://github.com/facugonz/pytorch_installing/blob/master/t81_558_class_07_1_gan_intro.ipynb </a><br>
      </div>

      <div class="card">
        <h2>December 09, 2024</h2>

        The code in section 6.2 contains the statement<br>
        <div class="code">
          import keras_preprocessing
        </div>

        Note that there is an underscore character in the name.<br><br>
        However, the command to install the package is<br>
        <div class="code">
          conda install -c conda-forge keras-preprocessing
        </div>
        Note that package has a hyphen in the name.<br><br>
        Make sure you are in the correct conda environment before installing, for example<br>

        <br>
        <div class="code">
          conda activate jh_class
        </div>

      </div>

      <div class="card">
        <h2>December 12, 2024</h2>

        Using NVlink with dual 3090's and C++ code:<br><br>

        <a href="https://www.reddit.com/r/LocalLLaMA/comments/16ubkyq/comment/li7lpqk/">
          https://www.reddit.com/r/LocalLLaMA/comments/16ubkyq/comment/li7lpqk/ </a><br>
        <a href="https://github.com/ggerganov/llama.cpp">
          https://github.com/ggerganov/llama.cpp
        </a><br>

        The author of the reddit comment, tomz17 states that he made a modification to ggml_cuda.cu that enables
        utilization of NVlink, but is unaware whether the change has been incorporated in the latest version of
        llama.cpp.

      </div>

      <div class="card">
        <h2>December 18, 2024</h2>
        The paperclips example in the lesson Part 6.2: Regression Convolutional Neural Networks<br>
        is also on Kaggle<br>
        <a href="https://www.kaggle.com/datasets/jeffheaton/count-the-paperclips">
          https://www.kaggle.com/datasets/jeffheaton/count-the-paperclips
        </a><br>
        plus a few extras, for example the code for generating the training data<br>
        <a href="https://www.kaggle.com/code/jeffheaton/generate-paperclips">
          https://www.kaggle.com/code/jeffheaton/generate-paperclips
        </a><br>

        <p>
          Jeff Heaton's examples use the ImageDataGenerator Class to prepare the image data.<br>

          However, In TensorFlow version 2.10, ImageDataGenerator is deprecated.<br>
          Instead, use tf.data going forward.<br>

          <a href="https://www.scaler.com/topics/keras/image-data-pipelines-in-keras/">
            https://www.scaler.com/topics/keras/image-data-pipelines-in-keras/ </a><br>

          This page contains an example with tf.data and the CIFAR-10 Dataset from the keras library.

        </p>
      </div>

      <div class="card">
        <h2>December 21, 2024</h2>
        Keras Image classification from scratch example:<br>

        <a href="https://keras.io/examples/vision/image_classification_from_scratch/">
          https://keras.io/examples/vision/image_classification_from_scratch/ </a><br>


        While running model.fit(), errors keep appearing<br>
        <div class="output">
          Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9
        </div>
        Other users have experienced the same problem:<br>
        <br>
        Corrupt files in the dogs_vs_cats dataset #2188
        <br>

        <a href="https://github.com/tensorflow/datasets/issues/2188">
          https://github.com/tensorflow/datasets/issues/2188
        </a><br>

        <p>
          A user on Kaggle has created a project with a smaller subset of the dog/cat images:<br><br>

          <a href="https://www.kaggle.com/datasets/abhinavnayak/catsvdogs-transformed/data">
            https://www.kaggle.com/datasets/abhinavnayak/catsvdogs-transformed/data
          </a><br>

        </p>

      </div>

      <div class="card">
        <h2>December 28, 2024</h2>

        <h5>Validation data used in model.fit function</h5>

        The preparation before model training in the model.fit function includes a step where the available data are
        split into training data and verification data.

        In some examples up to chapter 6.2, the model.fit function is called with the training data, and afterwards the
        model.predict function is called in order to find the accuracy of the trained model.
        <br>
        A typical output shows a loss value:

        <div class="code">
          10/10 [==============================] - 6s 486ms/step - loss: 1.0254
        </div>
        <br>
        In other examples such as in chapter 3.4, the model.fit function is called with the train data as well as the
        validation data.
        <br>
        A typical output shows a loss value:
        <div class="code">
          112/112 - 0s - loss: 1.1940 - val_loss: 1.1126 </div>
        <br>

        In the resnet example in chapter 6.3, the model.fit function is called with the train data as well as the
        validation data.

        <br>

        Here, a typical output shows a loss value as well as a validation loss value:

        <div class="code">
          250/250 [==============================] - 70s 256ms/step - loss: 73.1411 - rmse: 8.5523 - val_loss: 701.4966
          - val_rmse: 26.4858
        </div>

        <a href=""> </a><br>
      </div>

      <div class="card">
        <h2>December 31, 2024</h2>

        <h5>resnet links</h5>
        Writing ResNet from Scratch in PyTorch<br>
        <a href="https://www.digitalocean.com/community/tutorials/writing-resnet-from-scratch-in-pytorch">
          https://www.digitalocean.com/community/tutorials/writing-resnet-from-scratch-in-pytorch
        </a><br>
        <br>
        Keras Implementation of ResNet-50 (Residual Networks) Architecture from Scratch<br>
        <a href="https://machinelearningknowledge.ai/keras-implementation-of-resnet-50-architecture-from-scratch/">
          https://machinelearningknowledge.ai/keras-implementation-of-resnet-50-architecture-from-scratch/ </a><br>
        <br>
        github repository: Residual Networks With Examples<br>
        <a href="https://github.com/AnasBrital98/CNN-From-Scratch">
          https://github.com/AnasBrital98/CNN-From-Scratch </a><br>
        <br>
        Residual Networks With Examples<br>
        <a href="https://medium.com/@AnasBrital98/residual-networks-with-examples-80b47cacecf4">
          https://medium.com/@AnasBrital98/residual-networks-with-examples-80b47cacecf4 </a><br>


        Keras Applications<br>
        <a href="https://keras.io/api/applications/#usage-examples-for-image-classification-models">
          https://keras.io/api/applications/#usage-examples-for-image-classification-models </a><br>
        <br>
        Transfer learning & fine-tuning<br>
        <a href="https://keras.io/guides/transfer_learning/">
          https://keras.io/guides/transfer_learning/ </a><br>

        <a href=""> </a><br>

        <a href=""> </a><br>


      </div>

      <div class="card">
        <h2>Date</h2>
        <a href=""> </a><br>
      </div>


    </div>

    <div class="rightcolumn">
      <div class="card">
        <h3>Posts by Date</h3>
        <a href="AI_learning_2023_02_feb.html">
          AI_learning_2023_02_feb.html</a><br>
        <a href="AI_learning_2023_03_mar.html">
          AI_learning_2023_03_mar.html</a><br>
        <br>
      </div>

      <div class="card">
        <h3>Follow Me</h3>
        <a href="https://discord.gg/F7KQySEW"><img src="../../images/discord.png" alt="discord" height="30"></a>
      </div>

    </div>



  </div>


  <div class="footer">
    <h3>Modified July 2023</h3>
  </div>
</body>

</html>